{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.chunk import *\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn import svm, cross_validation, metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question dictionary\n",
    "dic_wh = {'Who': 1, 'When': 2, 'Where': 3, 'How': 4, 'What': 5, 'Which': 6,'Whose': 7, 'Others':8}\n",
    "dic_firstword_pos = {'VBD': 1,'NN': 2, 'VBZ': 3, 'MD': 4, 'VBP': 5, 'JJ': 6, 'CD': 7, 'VB': 8, 'VBG':9,'NNS': 10, 'PRP': 11, 'WDT': 12, 'NNP': 13,'RB': 14}\n",
    "dic_label = {'ABBR': 0, 'DESC': 1, 'ENTY': 2, 'HUM': 3, 'LOC': 4, 'NUM': 5, 'Other': 6}\n",
    "dic_secondword_pos = {'PRP$': 1,'VBG': 2,'VBD': 3,'VBP': 4,'WDT': 5,'JJ': 6,'VBZ': 7,'DT': 8,'NN': 9,'POS':10,'.':11,'PRP':12,'RB':13,':':14,'NNS':15,'NNP':16,'VB':17,'CC':18,'VBN':19,'IN':20,'CD':21,'MD':22,'NNPS':23,'JJS':24,'JJR':25}\n",
    "final_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_question(question):\n",
    "    sentence = question\n",
    "    token = nltk.word_tokenize(sentence)\n",
    "    word_list = nltk.pos_tag(token)\n",
    "    wh = word_list[0][0]\n",
    "    fw_pos = word_list[1][1]\n",
    "    sw_pos = word_list[2][1]\n",
    "\n",
    "    #find out what kind of question\n",
    "    sub = []\n",
    "    if dic_wh.has_key(wh):\n",
    "        sub.append(dic_wh(wh))\n",
    "        else:\n",
    "            sub.append(8)\n",
    "    \n",
    "    \n",
    "    #number of NNP\n",
    "    count = 0\n",
    "    for item in word_list:\n",
    "        if item[1] == 'NNP':\n",
    "            count = count + 1\n",
    "            \n",
    "    sub.append(count)\n",
    "    \n",
    "    #first word pos label\n",
    "    if dic_firstword.has_key(fw_pos):\n",
    "        sub.append(dic_firstword(fw_pos))\n",
    "        else:\n",
    "            sub.append(15)\n",
    "            \n",
    "    #second word pos label\n",
    "    \n",
    "    if dic_secondword.has_key(sw_pos):\n",
    "        sub.append(dic_secondword[sw_pos])\n",
    "        else:\n",
    "            sub.append(26)\n",
    "            \n",
    "    \n",
    "    experiment = np.asarray(sub)\n",
    "    X = experiment\n",
    "    \n",
    "    result = clf.predict(X)\n",
    "    \n",
    "    for key, val in dic_label.iteritems():\n",
    "        if val == result:\n",
    "            return key\n",
    "    return 'No_question_type'\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create question training set\n",
    "path = 'train.txt'\n",
    "file = open(path)\n",
    "enc = preprocessing.OneHotEncoder(categorical_features = [0,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features\n",
    "label = []\n",
    "w_word = []\n",
    "first_word = []\n",
    "secd_word = []\n",
    "lengthof_NNP = []\n",
    "question = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_wh = {'Who':1, 'When':'2', 'Where':3, 'How':4, 'What':5, 'Which':6, 'Whose':7, 'Others':8}\n",
    "dic_firstword = {'VBD':1,'NN':2,'VBZ':3,'MD':4,'VBP':5,'JJ':6,'CD':7,'VB':8,'VBG':9,'NNS':10,'PRP':11,'WDT':12,'NNP':13,'RB':14}\n",
    "dic_label = {'ABBR':0,'DESC':1,'ENTY':2,'HUM':3,'LOC':4,'NUM':5,'Other':6}\n",
    "dic_secondword = {'PRP$':1,'VBG':2,'VBD':3,'VBP':4,'WDT':5,'JJ':6,'VBZ':7,'DT':8,'NN':9,'POS':10,'.':11,'PRP':12,'RB':13,':':14,'NNS':15,'NNP':16,'VB':17,'CC':18,'VBN':19,'IN':20,'CD':21,'MD':22,'NNPS':23,'JJS':24,'JJR':25}\n",
    "final_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in file:\n",
    "    token = nltk.word_tokenize(row.split(' ',1)[1].replace('\\n',''))\n",
    "    pos_tags = nltk.pos_tag(token)\n",
    "    label = row.split(':',1)[0]\n",
    "    sub = []\n",
    "    #w_word\n",
    "    if dic_wh.has_key(pos_tags[0][0]):\n",
    "        sub.append(dic_wh[pos_tags[0][0]])\n",
    "    else:\n",
    "        sub.append(8)\n",
    "        \n",
    "    #length of NNP\n",
    "    count = 0\n",
    "    for item in pos_tags:\n",
    "        if item[1] == 'NNP':\n",
    "            count = count + 1\n",
    "    sub.append(count)\n",
    "    \n",
    "    #first_non wh word POS label\n",
    "    if dic_firstword.has_key(pos_tags[1][1]):\n",
    "        sub.append(dic_firstword[pos_tags[1][1]])\n",
    "    else:\n",
    "        sub.append(15)\n",
    "        \n",
    "    #second_word POS label\n",
    "    if dic_secondword.has_key(pos_tags[2][1]):\n",
    "        sub.append(dic_secondword[pos_tags[2][1]])\n",
    "    else:\n",
    "        sub.append(6)\n",
    "    final_train.append(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train = np.asarray(final_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "X = final_train[:,0:4]\n",
    "y = final_train[:,4]\n",
    "clf.fit(X,y)\n",
    "result = clf.predict(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
