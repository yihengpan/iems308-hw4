{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import math as m\n",
    "import operator\n",
    "from fractions import Fraction\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question term generator\n",
    "def Question_term(question):\n",
    "    stop = set(stopwords.words('english'))\n",
    "    pattern = r'[^A-Za-z0-9\\s]+'\n",
    "    question = re.sub(pattern,'', question)\n",
    "    token = nltk.word_tokenize(question)\n",
    "    cach = []\n",
    "    for word in token:\n",
    "        if word not in stop:\n",
    "            cach.append(word)\n",
    "    pos_tags = nltk.pos_tag(cach)\n",
    "\n",
    "    query_term = {}\n",
    "\n",
    "    for item in pos_tags:\n",
    "        if item[0] != 'Which' and item[0] != 'What' and item[0] != 'Where' and item[0] != 'When' and item[0] != 'Who' and item[0] != 'Whose' and item[0] != 'How' and  item[0] not in query_term:\n",
    "            query_term[item[0]] = 1\n",
    "        elif item[0] != 'Which' and item[0] != 'What' and item[0] != 'Where' and item[0] != 'When' and item[0] != 'Who' and item[0] != 'Whose' and item[0] != 'How' and item[0] in query_term:\n",
    "            query_term[item[0]] = query_term[item[0]] + 1\n",
    "\n",
    "    return query_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the document which contains at least one of the keywords\n",
    "def DocumentRetrieve(path, keywords):\n",
    "    file = open(path)\n",
    "    flag = False\n",
    "    for row in file:\n",
    "        row = row.replace('\\n', '')\n",
    "        row = row.replace('\\r', '')\n",
    "        row = row.split()\n",
    "        \n",
    "        for word in row:\n",
    "            if keywords.has_key(word):\n",
    "                flag = True\n",
    "                break\n",
    "                \n",
    "    if flag:\n",
    "        return path\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score the file that contains keywords\n",
    "def TF_IDF(keywords, All_relevant_Document, totalNum):\n",
    "    qtf = keywords\n",
    "    df = Document_Frequency(keywords, All_relevant_Document)\n",
    "    total_tf = {}\n",
    "    \n",
    "    for document in All_relevant_Document:\n",
    "        tf = Term_Frequency(keywords, document)\n",
    "        if tf != {}:\n",
    "            total_tf[document] = tf\n",
    "            \n",
    "    TFIDF = {}\n",
    "    for key,val in total_tf.items():\n",
    "        max_term = maximumTerm(key)\n",
    "        term = val\n",
    "        score = 0\n",
    "        for eachterm, value in term.iteritems():\n",
    "            TF = 0.5 + (0.5 * value / max_term)\n",
    "            IDF = m.log(Fraction(totalNum, df[eachterm]))\n",
    "            \n",
    "            tf_idf = TF * IDF\n",
    "            score = score + tf_idf\n",
    "            \n",
    "        if score != 0:\n",
    "            TFIDF[key] = score\n",
    "            \n",
    "        return sorted(TFIDF.iteritems(), key = operator.itemgetter(1), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the maximum term frequency of specific document\n",
    "def maximumTerm(Document):\n",
    "    file = open(Document)\n",
    "    Maximum_term = {}\n",
    "    stop = set(stopwords.words('English'))\n",
    "    for row in file:\n",
    "        row = row.replace('\\n','')\n",
    "        words = row.split(' ')\n",
    "        for word in words:\n",
    "            if word not in stop and word.lower() not in stop:\n",
    "                if not Maximum_term.has_key(word):\n",
    "                    Maximum_term[word] = 1\n",
    "                else:\n",
    "                    Maximum_term[word] = Maximum_term[word] + 1\n",
    "                    \n",
    "    return max(Maximum_term.iteritems(), key = operator.itemgetter(1))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute document_frequency\n",
    "def Document_Frequency(queryterms, All_relevant_Document):\n",
    "    df = dict.fromkeys(queryterms.keys(), 0)\n",
    "    for term in df:\n",
    "        for document in All_relevant_Document:\n",
    "            flag = False\n",
    "            file = open(document)\n",
    "            for row in file:\n",
    "                row = row.replace('\\n', '')\n",
    "                words = row.split(' ')\n",
    "                for word in words:\n",
    "                    if word == term:\n",
    "                        df[term] = df[term] + 1\n",
    "                        flag = True\n",
    "                        break\n",
    "                if flag == True:\n",
    "                    break\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute term_frequency\n",
    "def Term_Frequency(queryterms, Document):\n",
    "    tf = {}\n",
    "    file = open(Document)\n",
    "    for row in file:\n",
    "        row = row.replace('\\n','')\n",
    "        words = row.split(' ')\n",
    "        for word in words:\n",
    "            if queryterms.has_key(word) and not tf.has_key(word):\n",
    "                tf[word] = 1\n",
    "            elif queryterms.has_key(word) and tf.has_key(word):\n",
    "                tf[word] = tf[word] + 1\n",
    "    \n",
    "    return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find Num Documents with high score\n",
    "def Document_subset(Document, Num):\n",
    "    result = []\n",
    "    for i in range(0, Num):\n",
    "        result.append(Document[i][0])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def All_Document(key_words):\n",
    "    All_relevant_Document = []\n",
    "    for year in range(3,5):\n",
    "        for month in range(1,13):\n",
    "            for day in range(1,32):\n",
    "                if month < 10 and day < 10:\n",
    "                    file_path ='201' + str(year) + '/' + '201' + str(year) + '-0' + str(month) + '-0' + str(day) + '.txt'\n",
    "                elif month < 10 and day >= 10:\n",
    "                    file_path ='201' + str(year) + '/' + '201' + str(year) + '-0' + str(month) + '-' + str(day) + '.txt'\n",
    "                elif month > 10 and day < 10:\n",
    "                    file_path ='201' + str(year) + '/' + '201' + str(year) + '-' + str(month) + '-0' + str(day) + '.txt'\n",
    "                else:\n",
    "                    file_path ='201' + str(year) + '/' + '201' + str(year) + '-' + str(month) + '-' + str(day) + '.txt'\n",
    "                    document = ''\n",
    "                try:\n",
    "                    document = DocumentRetrieve(file_path,key_words)\n",
    "                except Exception:\n",
    "                    continue\n",
    "                if document != '':\n",
    "                    All_relevant_Document.append(document)\n",
    "    \n",
    "    return All_relevant_Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unemployment': 1, 'rate': 1}\n"
     ]
    }
   ],
   "source": [
    "question = 'What is the unemployment rate?'\n",
    "queryterms = Question_term(question)\n",
    "print(queryterms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_relevant_Document = All_Document(queryterms)\n",
    "ans = TF_IDF(queryterms,All_relevant_Document,len(All_relevant_Document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
